# =============================================================================
# BMAD-METHOD Qdrant Memory Integration - Environment Configuration
# =============================================================================
# Copy this file to .env and customize for your project:
#   cp .env.example .env
#
# IMPORTANT: Never commit .env to git! It's already in .gitignore
# =============================================================================

# -----------------------------------------------------------------------------
# QDRANT CONNECTION
# -----------------------------------------------------------------------------

# Qdrant server URL
# - Local Docker: http://localhost:16350 (custom port to avoid conflicts)
# - Qdrant Cloud: https://your-cluster-url.qdrant.io
# NOTE: Port 16350 chosen to avoid conflicts with other Qdrant instances
QDRANT_URL=http://localhost:16350

# Qdrant API key (required for Qdrant Cloud, optional for local)
# Leave empty for local development without authentication
QDRANT_API_KEY=

# Qdrant log level (DEBUG, INFO, WARN, ERROR)
# Production: INFO or WARN
# Development: DEBUG
QDRANT_LOG_LEVEL=INFO

# Max search threads (0 = auto-detect based on CPU cores)
# 2025 Best Practice: Keep between 8-16 for optimal HNSW graph building
QDRANT_MAX_SEARCH_THREADS=0

# -----------------------------------------------------------------------------
# COLLECTION NAMES
# -----------------------------------------------------------------------------
# Three collections for three memory types (from proven patterns)

# Main knowledge collection - stores project-specific knowledge
# Types: architecture_decision, agent_spec, story_outcome, error_pattern,
#        database_schema, config_pattern, integration_example
QDRANT_KNOWLEDGE_COLLECTION=bmad-knowledge

# Best practices collection - stores universal patterns
# Types: best_practice
QDRANT_BEST_PRACTICES_COLLECTION=bmad-best-practices

# Agent memory collection - stores long-term chat memory
# Types: chat_memory
QDRANT_AGENT_MEMORY_COLLECTION=agent-memory

# -----------------------------------------------------------------------------
# EMBEDDING CONFIGURATION
# -----------------------------------------------------------------------------

# Embedding model for vector generation
# Options:
#   - sentence-transformers/all-MiniLM-L6-v2 (384 dim, fast, good quality)
#   - sentence-transformers/all-mpnet-base-v2 (768 dim, slower, better quality)
#   - OpenAI text-embedding-ada-002 (1536 dim, requires API key)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Vector dimension (must match your embedding model)
# - all-MiniLM-L6-v2: 384
# - all-mpnet-base-v2: 768
# - text-embedding-ada-002: 1536
EMBEDDING_DIMENSION=384

# OpenAI API key (only required if using OpenAI embeddings)
OPENAI_API_KEY=

# -----------------------------------------------------------------------------
# PROJECT METADATA
# -----------------------------------------------------------------------------

# Your project ID - used for multitenancy (group_id in metadata)
# This is CRITICAL for data separation in shared Qdrant instances
# Example: my-legal-ai-project, customer-portal, internal-tools
PROJECT_ID=my-bmad-project

# Project name for display
PROJECT_NAME=My BMAD Project

# -----------------------------------------------------------------------------
# PROVEN PATTERNS - TOKEN BUDGETS
# -----------------------------------------------------------------------------
# From Legal AI implementation (Problem 3)
# Agent-specific token budgets for context loading

# Per-shard token limit (HARD LIMIT)
MAX_TOKENS_PER_SHARD=300

# Agent-specific total budgets
AGENT_BUDGET_ARCHITECT=1500
AGENT_BUDGET_ANALYST=1200
AGENT_BUDGET_PM=1200
AGENT_BUDGET_DEVELOPER=1000
AGENT_BUDGET_TEA=1000
AGENT_BUDGET_TECH_WRITER=1000
AGENT_BUDGET_UX_DESIGNER=1000
AGENT_BUDGET_QUICK_FLOW=1000
AGENT_BUDGET_SCRUM_MASTER=800

# Default budget for unlisted agents
AGENT_BUDGET_DEFAULT=1000

# -----------------------------------------------------------------------------
# PROVEN PATTERNS - SEMANTIC SEARCH
# -----------------------------------------------------------------------------
# From Legal AI implementation (Problem 6)

# Minimum score threshold for search results (0.0 - 1.0)
# Validated across 50+ queries in Legal AI project
# - 0.8-1.0: Excellent (exact match)
# - 0.7-0.79: Very good (strong relevance)
# - 0.6-0.69: Good (useful context)
# - 0.5-0.59: Acceptable (DEFAULT)
# - Below 0.5: Filter out
MIN_SCORE_THRESHOLD=0.5

# Higher threshold for critical decisions (architecture)
ARCHITECTURE_THRESHOLD=0.7

# -----------------------------------------------------------------------------
# PROVEN PATTERNS - DUPLICATE DETECTION
# -----------------------------------------------------------------------------
# From Legal AI implementation (Problem 8)

# Semantic similarity threshold for duplicate detection (0.0 - 1.0)
# Two-stage detection: SHA256 hash + semantic similarity
# Higher values = stricter matching (fewer false positives)
# Production-validated: 0.85 (prevents duplicates without false positives)
SIMILARITY_THRESHOLD=0.85

# Enable duplicate detection (true/false)
ENABLE_DUPLICATE_DETECTION=true

# -----------------------------------------------------------------------------
# PROVEN PATTERNS - VALIDATION
# -----------------------------------------------------------------------------
# From Legal AI implementation (Problems 4, 7)

# Minimum content length for knowledge entries (characters)
MIN_CONTENT_LENGTH=100

# Maximum content length for knowledge entries (characters)
MAX_CONTENT_LENGTH=50000

# Require file:line references (format: src/path/file.py:89-234)
# From Legal AI: REQUIRED for actionable memories
REQUIRE_FILE_REFERENCES=true

# Enable metadata validation (JSON schema enforcement)
ENABLE_METADATA_VALIDATION=true

# Enable pre-storage validation
ENABLE_PRE_STORAGE_VALIDATION=true

# -----------------------------------------------------------------------------
# MEMORY MODE CONFIGURATION
# -----------------------------------------------------------------------------
# From proven patterns: Dual access (Problem 2)

# Memory access mode:
#   - mcp: MCP tools only (main Claude session)
#   - python: Python API only (subprocess agents)
#   - hybrid: Both available (RECOMMENDED for BMAD)
MEMORY_MODE=hybrid

# Enable fallback to file-based memory if Qdrant unavailable
ENABLE_MEMORY_FALLBACK=true

# File-based memory location (fallback)
MEMORY_FALLBACK_DIR=./_bmad/_memory

# -----------------------------------------------------------------------------
# MONITORING CONFIGURATION
# -----------------------------------------------------------------------------

# Grafana admin credentials
# IMPORTANT: Change these in production!
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin

# Enable anonymous Grafana access (disable in production)
GRAFANA_ANONYMOUS=false

# Prometheus scrape interval (seconds)
# 2025 Best Practice: 15-30s for most workloads
PROMETHEUS_SCRAPE_INTERVAL=30s

# Metrics retention period (days)
PROMETHEUS_RETENTION_DAYS=30

# -----------------------------------------------------------------------------
# STREAMLIT DASHBOARD
# -----------------------------------------------------------------------------

# Enable Streamlit dashboard
ENABLE_STREAMLIT_DASHBOARD=true

# Streamlit server configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# Performance settings (2025 best practices)
STREAMLIT_SERVER_MAX_UPLOAD_SIZE=200
STREAMLIT_SERVER_ENABLE_CORS=false
STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION=true

# -----------------------------------------------------------------------------
# WORKFLOW INTEGRATION
# -----------------------------------------------------------------------------
# From proven patterns: Workflow hook timing (Problem 5)

# Enable pre-work memory search (Step 1.5)
ENABLE_PRE_WORK_SEARCH=true

# Enable post-work memory storage (Step 6.5)
ENABLE_POST_WORK_STORAGE=true

# Pre-work search timeout (seconds)
PRE_WORK_SEARCH_TIMEOUT=10

# Post-work storage is async (non-blocking)
POST_WORK_STORAGE_ASYNC=true

# -----------------------------------------------------------------------------
# LOGGING & DEBUGGING
# -----------------------------------------------------------------------------

# Application log level (DEBUG, INFO, WARN, ERROR)
LOG_LEVEL=INFO

# Enable verbose logging for debugging
VERBOSE_LOGGING=false

# Log file location
LOG_FILE=./logs/bmad-memory.log

# Enable request logging (all API calls to Qdrant)
ENABLE_REQUEST_LOGGING=false

# -----------------------------------------------------------------------------
# SECURITY SETTINGS (Production)
# -----------------------------------------------------------------------------

# Enable TLS for Qdrant (production only)
# Requires certificate configuration in qdrant_config/
QDRANT_ENABLE_TLS=false

# TLS certificate paths (if QDRANT_ENABLE_TLS=true)
QDRANT_TLS_CERT_PATH=./certs/server.crt
QDRANT_TLS_KEY_PATH=./certs/server.key

# Enable authentication for Qdrant API
QDRANT_ENABLE_AUTH=false

# API key for Qdrant authentication (if QDRANT_ENABLE_AUTH=true)
QDRANT_AUTH_API_KEY=

# -----------------------------------------------------------------------------
# DEVELOPMENT SETTINGS
# -----------------------------------------------------------------------------

# Enable development mode (extra logging, hot reload)
DEV_MODE=true

# Enable Qdrant web UI
ENABLE_QDRANT_WEB_UI=true

# Enable profiling (performance analysis)
ENABLE_PROFILING=false

# Seed data population on startup
POPULATE_SEED_DATA=false

# -----------------------------------------------------------------------------
# ADVANCED SETTINGS
# -----------------------------------------------------------------------------

# Cache TTL for embeddings (seconds)
# Reduces embedding API calls for duplicate content
EMBEDDING_CACHE_TTL=3600

# Batch size for bulk operations
BULK_OPERATION_BATCH_SIZE=100

# Max concurrent Qdrant connections
MAX_QDRANT_CONNECTIONS=10

# Connection pool timeout (seconds)
QDRANT_CONNECTION_TIMEOUT=30

# Retry configuration
MAX_RETRY_ATTEMPTS=3
RETRY_BACKOFF_FACTOR=2

# -----------------------------------------------------------------------------
# FEATURE FLAGS
# -----------------------------------------------------------------------------

# Enable experimental features (use with caution)
ENABLE_EXPERIMENTAL_FEATURES=false

# Enable code snippet storage (Problem 10: 3-10 lines save 92% time)
ENABLE_CODE_SNIPPETS=true

# Enable agent-specific memory type filtering (Problem 9)
ENABLE_AGENT_FILTERING=true

# Enable auto-pruning of low-quality memories
ENABLE_AUTO_PRUNING=false
AUTO_PRUNE_SCORE_THRESHOLD=0.3

# -----------------------------------------------------------------------------
# NOTES
# -----------------------------------------------------------------------------
#
# This configuration implements all 10 proven patterns from Legal AI:
# 1. Wrapper Script Bridge - Workflow integration settings
# 2. Dual Access - MEMORY_MODE=hybrid
# 3. Token Budget Enforcement - Agent-specific budgets
# 4. File:Line References - REQUIRE_FILE_REFERENCES=true
# 5. Workflow Hook Timing - Pre/post-work settings
# 6. Score Threshold 0.5 - MIN_SCORE_THRESHOLD=0.5
# 7. Metadata Validation - ENABLE_METADATA_VALIDATION=true
# 8. Duplicate Detection - SIMILARITY_THRESHOLD=0.85
# 9. Agent-Specific Memory Types - ENABLE_AGENT_FILTERING=true
# 10. Code Snippets - ENABLE_CODE_SNIPPETS=true
#
# Production Metrics Target (from Legal AI):
# - Token savings: ≥85%
# - Search latency: <1 second
# - Storage latency: <500ms
# - Data quality: 100%
# - Cache efficiency: ≥95%
# - Duplicates: 0
# =============================================================================
