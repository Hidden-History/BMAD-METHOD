# BMAD METHOD - Qdrant Memory Integration

## Project Overview

**BMAD METHOD** is an AI-driven agile development framework with 21 specialized agents and 50+ workflows. This feature branch adds **long-term memory capabilities** using Qdrant vector database.

**Current Task:** Integrate three types of persistent, searchable memory:
1. **Chat Memory** - Long-term conversation context
2. **Project Memory** - Architecture decisions, story outcomes, error patterns
3. **Best Practices** - Universal patterns and proven solutions

**Status:** Foundation phase - setting up infrastructure and core patterns

---

## Critical Context

### This is a PROVEN Implementation

All patterns come from a **production Legal AI project** with validated metrics:
- 85% token savings (1,200 tokens vs 8,000 tokens)
- <1 second search latency
- 100% data quality (1,206 shards, zero duplicates)
- 99% cache efficiency

**DO NOT deviate from these proven patterns without strong justification.**

### Reference Materials (Parent Directory)

```
../_project/                        # Our workspace (NEVER commit)
  â””â”€â”€ plans/
      â””â”€â”€ streamed-sleeping-flurry.md     # Complete implementation plan
  â””â”€â”€ session-notes/
      â””â”€â”€ 2026-01-03-initial-setup.md     # Latest session handoff

../_reference/                      # Source materials (NEVER commit)
  â””â”€â”€ guides/
      â”œâ”€â”€ BMAD_MEMORY_IMPLEMENTATION_EXPERIENCE.md  # ðŸ”¥ PRIMARY REFERENCE
      â”œâ”€â”€ bmad-qdrant-complete-guide.md
      â”œâ”€â”€ bmad-qdrant-monitoring-plan.md
      â””â”€â”€ bmad-qdrant-memory-guide.md
```

**ALWAYS read `BMAD_MEMORY_IMPLEMENTATION_EXPERIENCE.md` before implementing any memory feature.**

---

## 10 Proven Patterns (ALL REQUIRED)

These patterns are **non-negotiable** - they solved real production problems:

### 1. Wrapper Script Bridge
**Problem:** BMAD workflows are declarative (XML/YAML) and can't call Python directly
**Solution:** Thin Python wrapper scripts in `.bmad/bmm/workflows/tools/`
**Example:** `pre-work-search.py`, `post-work-store.py`

### 2. Dual Access
**Problem:** Subprocess agents can't inherit MCP connections
**Solution:** Provide BOTH MCP tools (main session) AND Python API (subprocess agents)

### 3. Token Budget Enforcement
**Problem:** Different agents need different context amounts
**Solution:** Agent-specific budgets (800-1500 tokens) enforced in code
**Config:**
```python
AGENT_TOKEN_BUDGETS = {
    "architect": 1500,
    "analyst": 1200,
    "pm": 1200,
    "dev": 1000,
    "tea": 1000,
    "sm": 800,
}
MAX_TOKENS_PER_SHARD = 300
```

### 4. File:Line References REQUIRED
**Problem:** Vague memories aren't actionable
**Solution:** Hard validation requiring format `src/path/file.py:89-234`
**Enforcement:** Storage rejected if references missing

### 5. Workflow Hook Timing
**Problem:** Wrong timing causes context misses
**Solution:**
- Step 1.5: Pre-work search (BEFORE implementation)
- Step 6.5: Post-work storage (AFTER verification)

### 6. Score Threshold 0.5
**Problem:** Irrelevant memories waste tokens
**Solution:** Validated threshold across 50+ queries
**Quality:**
- 0.8-1.0: Excellent (exact match)
- 0.6-0.79: Very good (strong relevance)
- **0.5-0.59: Acceptable** (DEFAULT THRESHOLD)
- <0.5: Filter out

### 7. Metadata Validation
**Problem:** Missing metadata breaks search
**Solution:** JSON schema validation BEFORE storage
**Required Fields:** unique_id, type, story_id, epic_id, component, importance, created_at, agent, group_id

### 8. Duplicate Detection
**Problem:** Duplicates waste storage and confuse search
**Solution:** Two-stage detection:
1. SHA256 hash (exact duplicates)
2. Semantic similarity >0.85 (near duplicates)

### 9. Agent-Specific Memory Types
**Problem:** Wrong memory types clutter context
**Solution:** Filter by agent role (dev sees story_outcome, architect sees architecture_decision)

### 10. Code Snippets (3-10 lines)
**Problem:** File:line references require context switch
**Solution:** Include 3-10 line snippets inline
**Benefit:** 92% faster comprehension (2-3 min â†’ 10 sec)

---

## Implementation Roadmap

### Week 1: Foundation + Monitoring (IN PROGRESS)
- [x] Clone repo and create feature branch
- [x] Setup .gitignore
- [ ] Port docker-compose.yml (Qdrant + Grafana + Prometheus)
- [ ] Port .env.example
- [ ] Port requirements.txt
- [ ] Test: Qdrant startup
- [ ] Test: Grafana at localhost:3000
- [ ] Create collections

### Week 2: Python Core
- [ ] Implement `src/core/memory/` with all proven patterns
- [ ] Create 8 JSON schemas
- [ ] Implement validation scripts
- [ ] Test search and storage

### Week 3: Workflow Integration
- [ ] Create wrapper scripts
- [ ] Modify dev-story workflow
- [ ] Test all 3 memory types

### Week 4: Auto-Setup + Documentation
- [ ] Create `scripts/memory-setup.sh`
- [ ] Implement Streamlit dashboard
- [ ] Create CLI tools
- [ ] Write documentation

---

## File Structure (Target)

```
BMAD-METHOD/
â”œâ”€â”€ docker-compose.yml              # Qdrant + monitoring
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ src/core/
â”‚   â”œâ”€â”€ memory/                     # NEW: Memory system
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_hooks.py     # PROVEN pattern
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_hooks.py
â”‚   â”‚   â”‚   â”œâ”€â”€ project_hooks.py
â”‚   â”‚   â”‚   â””â”€â”€ best_practices_hooks.py
â”‚   â”‚   â”œâ”€â”€ schemas/               # 8 JSON schemas
â”‚   â”‚   â””â”€â”€ validation/
â”‚   â”‚
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ tools/                  # NEW: Bridge scripts
â”‚           â”œâ”€â”€ pre-work-search.py
â”‚           â”œâ”€â”€ post-work-store.py
â”‚           â””â”€â”€ load-chat-context.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ memory-setup.sh            # Auto-setup
â”‚   â””â”€â”€ memory/
â”‚       â”œâ”€â”€ create-collections.py
â”‚       â”œâ”€â”€ streamlit-dashboard.py
â”‚       â””â”€â”€ test-memory.py
â”‚
â””â”€â”€ monitoring/
    â”œâ”€â”€ grafana/dashboards/
    â””â”€â”€ prometheus/prometheus.yml
```

---

## Development Guidelines

### Git Workflow
- **Branch:** `feature/qdrant-memory-foundation`
- **Commits:** Conventional commits (`feat(memory): description`)
- **DO NOT commit:** `.env`, `qdrant_storage/`, anything in `../_project/` or `../_reference/`

### Code Style
- Follow existing BMAD patterns
- Keep solutions simple (avoid over-engineering)
- Only add what's directly requested
- No premature abstractions

### Testing
- Test Qdrant connectivity before implementing features
- Validate against Legal AI metrics (85% token savings, <1s search)
- Test all 3 memory types with real workflows

### Security
- **NEVER commit secrets** (API keys, tokens, passwords)
- Validate all user input
- Use parameterized queries
- Check file permissions on sensitive files

---

## Key Commands

### Docker
```bash
docker-compose up -d                # Start Qdrant + monitoring
docker-compose down                 # Stop services
docker-compose logs -f qdrant       # View Qdrant logs
```

### Qdrant
- Dashboard: http://localhost:16350/dashboard
- Health: http://localhost:16350/health
- Metrics: http://localhost:16350/metrics
- gRPC: localhost:16351

### Monitoring
- Grafana: http://localhost:13005 (admin/admin)
- Prometheus: http://localhost:19095
- Streamlit: http://localhost:18505

**Note:** Ports changed from defaults to avoid conflicts with existing containers:
- Qdrant: 6333â†’16350, 6334â†’16351
- Prometheus: 9090â†’19095
- Grafana: 3000â†’13005
- Streamlit: 8501â†’18505

### Memory CLI (Future)
```bash
bmad-memory status                  # Check system health
bmad-memory search "query"          # Search memories
bmad-memory recent --limit 10       # Show recent memories
```

---

## Production Metrics (Target)

Must match or exceed Legal AI results:

| Metric | Legal AI | Target | Status |
|--------|----------|--------|--------|
| Token savings | 85% | â‰¥85% | Not measured |
| Search latency | <1s | <1s | Not implemented |
| Storage latency | <500ms | <500ms | Not implemented |
| Data quality | 100% | 100% | Not implemented |
| Cache efficiency | 99% | â‰¥95% | Not implemented |
| Duplicates | 0 | 0 | Not implemented |

---

## Getting Help

### For Implementation Questions
1. **Read first:** `../_reference/guides/BMAD_MEMORY_IMPLEMENTATION_EXPERIENCE.md`
2. **Check plan:** `../_project/plans/streamed-sleeping-flurry.md`
3. **Review session notes:** `../_project/session-notes/`

### For Architecture Decisions
- All patterns are proven in production
- Don't deviate without strong justification
- Document deviations in `../_project/decisions/`

### For Session Continuity
- Update `../_project/session-notes/` after significant work
- Keep track of progress in `../_project/progress/`
- Update this file (.claude.md) if project context changes

---

## Important Constraints

### DO
âœ… Apply all 10 proven patterns exactly as documented
âœ… Reference BMAD_MEMORY_IMPLEMENTATION_EXPERIENCE.md frequently
âœ… Test against Legal AI production metrics
âœ… Keep code simple and focused
âœ… Validate file:line references
âœ… Enforce token budgets

### DON'T
âŒ Skip any of the 10 proven patterns
âŒ Commit secrets or environment files
âŒ Commit `_project/` or `_reference/` directories
âŒ Over-engineer solutions
âŒ Add features not in the plan
âŒ Deviate from proven patterns without justification

---

## Next Session Checklist

Before ending a session:
- [ ] Update `../_project/session-notes/` with latest status
- [ ] Commit work to feature branch
- [ ] Update roadmap progress in this file
- [ ] Document any deviations or decisions
- [ ] Note any blockers or questions

Before starting a session:
- [ ] Read latest session notes
- [ ] Review current roadmap status
- [ ] Check for any pending decisions
- [ ] Verify environment is running (docker-compose)

---

**Last Updated:** 2026-01-03
**Current Phase:** Week 1 - Foundation + Monitoring
**Branch:** feature/qdrant-memory-foundation
**Status:** Directory structure complete, ready for infrastructure setup
